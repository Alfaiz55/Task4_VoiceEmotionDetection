ğŸ¤ Voice Emotion Detection
This project is part of my NullClass Internship Task 4.
It detects human emotions from voice recordings using Deep Learning (CNN + LSTM) and provides a simple GUI to test with audio files or live recording.


ğŸ“‚ Project Structure

â”œâ”€â”€ audio.py                 # GUI for recording/uploading audio and predicting emotion  
â”œâ”€â”€ voice_emotion_best.keras # Trained model file  
â”œâ”€â”€ label_encoder.pkl        # Saved LabelEncoder for mapping predictions to emotion labels  
â”œâ”€â”€ requirements.txt         # List of required Python libraries  
â”œâ”€â”€ training_notebook.ipynb  # Jupyter notebook with full preprocessing, training & evaluation  


âš¡ Features
Preprocessing using MFCC + Delta + Delta-Delta features
Balanced training with CREMA-D dataset
CNN + LSTM architecture for sequential feature learning
GUI built with Tkinter

Options in GUI:
ğŸ™ï¸ Record Voice (Red Button)
ğŸ“‚ Upload Audio File (Black Button)
âœ… Predict Emotion (Green Button)

Clear output message:
Example â†’ ğŸ¯ Predicted Emotion: Happy voice

ğŸ¯ Emotions Detected

Angry
Happy
Sad
Fear
Neutral
Disgust

âš™ï¸ Installation

Clone the repository and install dependencies:
git clone <your_repo_link>
cd voice_emotion_detection
pip install -r requirements.txt

ğŸ“Š Model Performance::--
âœ… Achieved 70%+ validation accuracy on CREMA-D dataset
Early stopping & regularization to prevent overfitting

ğŸ“¦ Files to Submit::--
voice_emotion_best.keras â†’ Trained model
label_encoder.pkl â†’ Label mapping
audio.py â†’ GUI
requirements.txt â†’ Dependencies
training_notebook.ipynb â†’ Training pipeline
